{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36d87884",
   "metadata": {},
   "source": [
    "# Simple Neural Collaborative Filtering (DMF-like)\n",
    "\n",
    "Chúng ta sẽ xây dựng một mô hình Neural Collaborative Filtering đơn giản (tương tự Deep Matrix Factorization) sử dụng PyTorch.\n",
    "Mô hình sẽ sử dụng cơ chế Learning Embeddings cho User và Item, sau đó kết hợp qua tích vô hướng (Dot Product) để dự đoán điểm đánh giá.\n",
    "\n",
    "### Các bước thực hiện:\n",
    "1.  Import thư viện và Load dữ liệu.\n",
    "2.  Tiền xử lý: Mapping UserID và MovieID sang dạng chỉ số (index).\n",
    "3.  Xây dựng PyTorch Dataset và DataLoader.\n",
    "4.  Định nghĩa mô hình Neural Network.\n",
    "5.  Huấn luyện (Training).\n",
    "6.  Đánh giá (Evaluation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c075640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Kiểm tra GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37cd8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dữ liệu\n",
    "# Lưu ý: Điều chỉnh đường dẫn nếu cần thiết\n",
    "train_path = 'ratings_train.csv'\n",
    "test_path = 'ratings_test.csv'\n",
    "\n",
    "# Đọc dữ liệu (chỉ lấy các cột cần thiết để tiết kiệm bộ nhớ nếu file lớn)\n",
    "cols = ['userId', 'movieId', 'rating']\n",
    "df_train = pd.read_csv(train_path, usecols=cols)\n",
    "df_test = pd.read_csv(test_path, usecols=cols)\n",
    "\n",
    "print(f\"Train size: {len(df_train)}\")\n",
    "print(f\"Test size: {len(df_test)}\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e763911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Encoding User and Movie IDs\n",
    "# Chúng ta cần map userId và movieId về khoảng [0, N) để dùng trong Embedding Layer\n",
    "\n",
    "# Gom tất cả user và item từ train và test để tạo mapping đầy đủ\n",
    "all_users = pd.concat([df_train['userId'], df_test['userId']]).unique()\n",
    "all_movies = pd.concat([df_train['movieId'], df_test['movieId']]).unique()\n",
    "\n",
    "# Tạo encoder\n",
    "user_encoder = LabelEncoder()\n",
    "movie_encoder = LabelEncoder()\n",
    "\n",
    "user_encoder.fit(all_users)\n",
    "movie_encoder.fit(all_movies)\n",
    "\n",
    "# Transform dữ liệu\n",
    "df_train['user_idx'] = user_encoder.transform(df_train['userId'])\n",
    "df_train['movie_idx'] = movie_encoder.transform(df_train['movieId'])\n",
    "\n",
    "df_test['user_idx'] = user_encoder.transform(df_test['userId'])\n",
    "df_test['movie_idx'] = movie_encoder.transform(df_test['movieId'])\n",
    "\n",
    "num_users = len(all_users)\n",
    "num_movies = len(all_movies)\n",
    "\n",
    "print(f\"Number of Users: {num_users}\")\n",
    "print(f\"Number of Movies: {num_movies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d019d85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingDataset(Dataset):\n",
    "    def __init__(self, user_indices, movie_indices, ratings):\n",
    "        self.users = torch.tensor(user_indices, dtype=torch.long)\n",
    "        self.movies = torch.tensor(movie_indices, dtype=torch.long)\n",
    "        self.ratings = torch.tensor(ratings, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.movies[idx], self.ratings[idx]\n",
    "\n",
    "# Tạo Dataset và DataLoader\n",
    "train_dataset = RatingDataset(df_train['user_idx'].values, df_train['movie_idx'].values, df_train['rating'].values)\n",
    "test_dataset = RatingDataset(df_test['user_idx'].values, df_test['movie_idx'].values, df_test['rating'].values)\n",
    "\n",
    "batch_size = 1024 # Batch size lớn giúp train nhanh hơn với dữ liệu lớn\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c31aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDMF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=64, hidden_dims=[64, 32]):\n",
    "        super(SimpleDMF, self).__init__()\n",
    "        \n",
    "        # User Embedding & MLP\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.user_layers = nn.ModuleList()\n",
    "        input_dim = embedding_dim\n",
    "        for dim in hidden_dims:\n",
    "            self.user_layers.append(nn.Linear(input_dim, dim))\n",
    "            self.user_layers.append(nn.ReLU())\n",
    "            input_dim = dim\n",
    "            \n",
    "        # Item Embedding & MLP\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        self.item_layers = nn.ModuleList()\n",
    "        input_dim = embedding_dim\n",
    "        for dim in hidden_dims:\n",
    "            self.item_layers.append(nn.Linear(input_dim, dim))\n",
    "            self.item_layers.append(nn.ReLU())\n",
    "            input_dim = dim\n",
    "            \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Embedding):\n",
    "                nn.init.normal_(m.weight, std=0.01)\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "        # User Tower\n",
    "        user_vec = self.user_embedding(user_indices)\n",
    "        for layer in self.user_layers:\n",
    "            user_vec = layer(user_vec)\n",
    "            \n",
    "        # Item Tower\n",
    "        item_vec = self.item_embedding(item_indices)\n",
    "        for layer in self.item_layers:\n",
    "            item_vec = layer(item_vec)\n",
    "            \n",
    "        # Normalize vectors for Cosine Similarity (optional, but typical for DMF)\n",
    "        # Hoặc dùng Dot Product trực tiếp. Ở đây dùng Dot Product đơn giản cho Regression.\n",
    "        # Nếu muốn đúng chuẩn DMF paper thì dùng Cosine similarity. \n",
    "        # Tuy nhiên với rating 1-5, dot product tự học độ lớn sẽ dễ hội tụ hơn.\n",
    "        \n",
    "        interaction = (user_vec * item_vec).sum(dim=1)\n",
    "        \n",
    "        return interaction\n",
    "\n",
    "# Khởi tạo mô hình\n",
    "model = SimpleDMF(num_users, num_movies).to(device)\n",
    "print(model)\n",
    "\n",
    "# Loss và Optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dc346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "num_epochs = 10\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for users, movies, ratings in train_loader:\n",
    "        users = users.to(device)\n",
    "        movies = movies.to(device)\n",
    "        ratings = ratings.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(users, movies)\n",
    "        loss = criterion(predictions, ratings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * users.size(0)\n",
    "        \n",
    "    avg_loss = total_loss / len(train_dataset)\n",
    "    train_losses.append(avg_loss)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Plot Loss\n",
    "plt.plot(train_losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475cf8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "predictions_list = []\n",
    "targets_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for users, movies, ratings in test_loader:\n",
    "        users = users.to(device)\n",
    "        movies = movies.to(device)\n",
    "        \n",
    "        preds = model(users, movies)\n",
    "        \n",
    "        predictions_list.extend(preds.cpu().numpy())\n",
    "        targets_list.extend(ratings.numpy())\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(targets_list, predictions_list))\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n",
    "\n",
    "# Example Predictions\n",
    "df_result = pd.DataFrame({'Actual': targets_list[:10], 'Predicted': predictions_list[:10]})\n",
    "print(df_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
