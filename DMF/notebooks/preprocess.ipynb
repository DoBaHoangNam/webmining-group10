{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c726b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths set, output dir: data\\processed\n"
     ]
    }
   ],
   "source": [
    "# Imports and paths\n",
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r'D:\\Project\\web_mining\\data\\data')\n",
    "PATHS = {\n",
    "    'movies': BASE / 'movies_metadata.csv',\n",
    "    'credits': BASE / 'credits.csv',\n",
    "    'keywords': BASE / 'keywords.csv',\n",
    "    'links': BASE / 'links.csv',\n",
    "    'ratings': BASE / 'ratings.csv',\n",
    "    'ratings_small': BASE / 'ratings_small.csv',\n",
    "}\n",
    "OUTDIR = Path('data/processed')\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "print('Paths set, output dir:', OUTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfd9e3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helpers ready\n"
     ]
    }
   ],
   "source": [
    "# Helper: safe parse JSON-like string columns (e.g., genres containing [{'id':..,'name':'..'}, ...])\n",
    "def safe_parse(x):\n",
    "    try:\n",
    "        return ast.literal_eval(x)\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "print('Helpers ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58f86246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: movies, credits, keywords, links, ratings_small\n",
      "movies rows= 45466 credits= 45476 ratings= 26024289\n"
     ]
    }
   ],
   "source": [
    "# Load main files (use low_memory for movies)\n",
    "movies_raw = pd.read_csv(PATHS['movies'], low_memory=False)\n",
    "credits_raw = pd.read_csv(PATHS['credits'])\n",
    "keywords_raw = pd.read_csv(PATHS['keywords'])\n",
    "links_raw = pd.read_csv(PATHS['links'])\n",
    "# use small ratings for quick dev, full ratings when needed\n",
    "ratings_small_raw = pd.read_csv(PATHS['ratings_small'])\n",
    "ratings_raw = pd.read_csv(PATHS['ratings'])\n",
    "print('Loaded: movies, credits, keywords, links, ratings_small')\n",
    "print('movies rows=', len(movies_raw), 'credits=', len(credits_raw), 'ratings=', len(ratings_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d233606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "036667a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chuyển đổi các cột JSON-like thành lists\n",
    "\n",
    "json_cols = [\n",
    "    \"genres\",\n",
    "    \"production_companies\",\n",
    "    \"production_countries\",\n",
    "    \"spoken_languages\",\n",
    "    \"belongs_to_collection\"\n",
    "]\n",
    "for col in json_cols:\n",
    "    movies[col] = movies[col].apply(safe_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fa0f2ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_belongs_to_collection(x):\n",
    "    if isinstance(x, dict):\n",
    "        return {\n",
    "            \"id\": x.get(\"id\"),\n",
    "            \"name\": x.get(\"name\")\n",
    "        }\n",
    "    return None\n",
    "movies[\"belongs_to_collection\"] = movies[\"belongs_to_collection\"].apply(\n",
    "    clean_belongs_to_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "50b81f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# release_date\n",
    "movies[\"release_date\"] = pd.to_datetime(\n",
    "    movies[\"release_date\"], errors=\"coerce\"\n",
    ")\n",
    "movies[\"release_year\"] = movies[\"release_date\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "411f8bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuẩn hóa numeric \n",
    "num_cols = [\n",
    "    \"budget\", \"revenue\", \"runtime\",\n",
    "    \"popularity\", \"vote_average\", \"vote_count\"\n",
    "]\n",
    "\n",
    "movies[num_cols] = movies[num_cols].apply(pd.to_numeric, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1a1e5593",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[\"overview\"] = movies[\"overview\"].fillna(\"\")\n",
    "movies[\"tagline\"] = movies[\"tagline\"].fillna(\"\")\n",
    "movies[\"runtime\"] = movies[\"runtime\"].fillna(movies[\"runtime\"].median())\n",
    "movies[\"budget\"] = movies[\"budget\"].fillna(0)\n",
    "movies[\"revenue\"] = movies[\"revenue\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919ad300",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop cột không cần thiết\n",
    "drop_cols = [\n",
    "    \"poster_path\", \"homepage\",\n",
    "    \"spoken_languages\", \"original_title\", \"original_language\",\n",
    "    \"imdb_id\"\n",
    "]\n",
    "\n",
    "movies = movies.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "23d3b36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.to_csv(\"movies_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c1dc5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean credits: \n",
    "credits = credits_raw.copy()\n",
    "credits[\"cast\"] = credits[\"cast\"].apply(safe_parse)\n",
    "credits[\"crew\"] = credits[\"crew\"].apply(safe_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f0de9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trích xuất top diễn viên chính\n",
    "def get_all_cast(cast_list):\n",
    "    if not isinstance(cast_list, list):\n",
    "        return []\n",
    "    return [c.get(\"name\") for c in cast_list if \"name\" in c]\n",
    "\n",
    "credits[\"top_cast\"] = credits[\"cast\"].apply(get_all_cast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c07bf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trích xuất đạo diễn\n",
    "def get_director(crew_list):\n",
    "    if not isinstance(crew_list, list):\n",
    "        return None\n",
    "    for person in crew_list:\n",
    "        if person.get(\"job\") == \"Director\":\n",
    "            return person.get(\"name\")\n",
    "    return None\n",
    "\n",
    "credits[\"director\"] = credits[\"crew\"].apply(get_director)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad51d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trích xuất biên kịch / producer\n",
    "def get_job(crew_list, job_name):\n",
    "    if not isinstance(crew_list, list):\n",
    "        return []\n",
    "    return [\n",
    "        p[\"name\"] for p in crew_list\n",
    "        if p.get(\"job\") == job_name\n",
    "    ]\n",
    "\n",
    "credits[\"writers\"] = credits[\"crew\"].apply(\n",
    "    lambda x: get_job(x, \"Writer\")\n",
    ")\n",
    "\n",
    "credits[\"producers\"] = credits[\"crew\"].apply(\n",
    "    lambda x: get_job(x, \"Producer\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fa24f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "credits_clean = credits.drop(columns=[\"cast\", \"crew\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fb7d321",
   "metadata": {},
   "outputs": [],
   "source": [
    "credits_clean.to_csv(\"credits_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6f86e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean keywords\n",
    "\n",
    "keywords = keywords_raw.copy()\n",
    "keywords[\"keywords\"] = keywords[\"keywords\"].apply(safe_parse)\n",
    "keywords[\"keyword_names\"] = keywords[\"keywords\"].apply(\n",
    "    lambda x: [k[\"name\"] for k in x] if isinstance(x, list) else []\n",
    ")\n",
    "keywords_clean = keywords.drop(columns=[\"keywords\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "404c85e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_clean.to_csv(\"keywords_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28a27846",
   "metadata": {},
   "outputs": [],
   "source": [
    "### train test split\n",
    "import pandas as pd\n",
    "\n",
    "# Đọc dữ liệu\n",
    "ratings = pd.read_csv(r\"D:\\Project\\web_mining\\data\\data\\ratings.csv\")\n",
    "\n",
    "# Đảm bảo timestamp là số (phòng lỗi)\n",
    "ratings[\"timestamp\"] = ratings[\"timestamp\"].astype(int)\n",
    "\n",
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "# Group theo userID\n",
    "for user_id, user_df in ratings.groupby(\"userId\"):\n",
    "    # Sort theo thời gian\n",
    "    user_df = user_df.sort_values(\"timestamp\")\n",
    "\n",
    "    # Xác định điểm chia\n",
    "    split_idx = int(len(user_df) * 0.85)\n",
    "\n",
    "    train_list.append(user_df.iloc[:split_idx])\n",
    "    test_list.append(user_df.iloc[split_idx:])\n",
    "\n",
    "# Gộp lại thành DataFrame\n",
    "train_df = pd.concat(train_list).reset_index(drop=True)\n",
    "test_df = pd.concat(test_list).reset_index(drop=True)\n",
    "\n",
    "train_df.to_csv(r\"D:\\Project\\web_mining\\notebooks\\ratings_train.csv\", index=False)\n",
    "test_df.to_csv(r\"D:\\Project\\web_mining\\notebooks\\ratings_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddc2ac9",
   "metadata": {},
   "source": [
    "**Next steps / notes**:\n",
    "- Run cells in order.\n",
    "- For large-scale work, use `pd.read_csv(..., chunksize=...)` for `ratings.csv`.\n",
    "- Adjust which features to extract (top-k cast, top keywords).\n",
    "- Consider storing intermediate results as parquet or Feather for speed.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
