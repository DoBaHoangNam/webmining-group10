{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c726b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths set, output dir: data\\processed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r'D:\\Project\\web_mining\\data\\data')\n",
    "PATHS = {\n",
    "    'movies': BASE / 'movies_metadata.csv',\n",
    "    'credits': BASE / 'credits.csv',\n",
    "    'keywords': BASE / 'keywords.csv',\n",
    "    'links': BASE / 'links.csv',\n",
    "    'ratings': BASE / 'ratings.csv',\n",
    "    'ratings_small': BASE / 'ratings_small.csv',\n",
    "}\n",
    "OUTDIR = Path('data/processed')\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "print('Paths set, output dir:', OUTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd9e3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helpers ready\n"
     ]
    }
   ],
   "source": [
    "def safe_parse(x):\n",
    "    try:\n",
    "        return ast.literal_eval(x)\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "print('Helpers ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f86246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: movies, credits, keywords, links, ratings_small\n",
      "movies rows= 45466 credits= 45476 ratings= 26024289\n"
     ]
    }
   ],
   "source": [
    "movies_raw = pd.read_csv(PATHS['movies'], low_memory=False)\n",
    "credits_raw = pd.read_csv(PATHS['credits'])\n",
    "keywords_raw = pd.read_csv(PATHS['keywords'])\n",
    "links_raw = pd.read_csv(PATHS['links'])\n",
    "ratings_small_raw = pd.read_csv(PATHS['ratings_small'])\n",
    "ratings_raw = pd.read_csv(PATHS['ratings'])\n",
    "print('Loaded: movies, credits, keywords, links, ratings_small')\n",
    "print('movies rows=', len(movies_raw), 'credits=', len(credits_raw), 'ratings=', len(ratings_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d233606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036667a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_cols = [\n",
    "    \"genres\",\n",
    "    \"production_companies\",\n",
    "    \"production_countries\",\n",
    "    \"spoken_languages\",\n",
    "    \"belongs_to_collection\"\n",
    "]\n",
    "for col in json_cols:\n",
    "    movies[col] = movies[col].apply(safe_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fa0f2ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_belongs_to_collection(x):\n",
    "    if isinstance(x, dict):\n",
    "        return {\n",
    "            \"id\": x.get(\"id\"),\n",
    "            \"name\": x.get(\"name\")\n",
    "        }\n",
    "    return None\n",
    "movies[\"belongs_to_collection\"] = movies[\"belongs_to_collection\"].apply(\n",
    "    clean_belongs_to_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b81f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[\"release_date\"] = pd.to_datetime(\n",
    "    movies[\"release_date\"], errors=\"coerce\"\n",
    ")\n",
    "movies[\"release_year\"] = movies[\"release_date\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411f8bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\n",
    "    \"budget\", \"revenue\", \"runtime\",\n",
    "    \"popularity\", \"vote_average\", \"vote_count\"\n",
    "]\n",
    "\n",
    "movies[num_cols] = movies[num_cols].apply(pd.to_numeric, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1a1e5593",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[\"overview\"] = movies[\"overview\"].fillna(\"\")\n",
    "movies[\"tagline\"] = movies[\"tagline\"].fillna(\"\")\n",
    "movies[\"runtime\"] = movies[\"runtime\"].fillna(movies[\"runtime\"].median())\n",
    "movies[\"budget\"] = movies[\"budget\"].fillna(0)\n",
    "movies[\"revenue\"] = movies[\"revenue\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919ad300",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\n",
    "    \"poster_path\", \"homepage\",\n",
    "    \"spoken_languages\", \"original_title\", \"original_language\",\n",
    "    \"imdb_id\"\n",
    "]\n",
    "\n",
    "movies = movies.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "23d3b36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.to_csv(\"movies_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1dc5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "credits = credits_raw.copy()\n",
    "credits[\"cast\"] = credits[\"cast\"].apply(safe_parse)\n",
    "credits[\"crew\"] = credits[\"crew\"].apply(safe_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0de9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_cast(cast_list):\n",
    "    if not isinstance(cast_list, list):\n",
    "        return []\n",
    "    return [c.get(\"name\") for c in cast_list if \"name\" in c]\n",
    "\n",
    "credits[\"top_cast\"] = credits[\"cast\"].apply(get_all_cast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c07bf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_director(crew_list):\n",
    "    if not isinstance(crew_list, list):\n",
    "        return None\n",
    "    for person in crew_list:\n",
    "        if person.get(\"job\") == \"Director\":\n",
    "            return person.get(\"name\")\n",
    "    return None\n",
    "\n",
    "credits[\"director\"] = credits[\"crew\"].apply(get_director)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad51d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job(crew_list, job_name):\n",
    "    if not isinstance(crew_list, list):\n",
    "        return []\n",
    "    return [\n",
    "        p[\"name\"] for p in crew_list\n",
    "        if p.get(\"job\") == job_name\n",
    "    ]\n",
    "\n",
    "credits[\"writers\"] = credits[\"crew\"].apply(\n",
    "    lambda x: get_job(x, \"Writer\")\n",
    ")\n",
    "\n",
    "credits[\"producers\"] = credits[\"crew\"].apply(\n",
    "    lambda x: get_job(x, \"Producer\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa24f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "credits_clean = credits.drop(columns=[\"cast\", \"crew\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fb7d321",
   "metadata": {},
   "outputs": [],
   "source": [
    "credits_clean.to_csv(\"credits_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f86e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = keywords_raw.copy()\n",
    "keywords[\"keywords\"] = keywords[\"keywords\"].apply(safe_parse)\n",
    "keywords[\"keyword_names\"] = keywords[\"keywords\"].apply(\n",
    "    lambda x: [k[\"name\"] for k in x] if isinstance(x, list) else []\n",
    ")\n",
    "keywords_clean = keywords.drop(columns=[\"keywords\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "404c85e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_clean.to_csv(\"keywords_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a27846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ratings = pd.read_csv(r\"D:\\Project\\web_mining\\data\\data\\ratings_small.csv\")\n",
    "\n",
    "ratings[\"timestamp\"] = ratings[\"timestamp\"].astype(int)\n",
    "\n",
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "for user_id, user_df in ratings.groupby(\"userId\"):\n",
    "    user_df = user_df.sort_values(\"timestamp\")\n",
    "    split_idx = int(len(user_df) * 0.80)\n",
    "    train_list.append(user_df.iloc[:split_idx])\n",
    "    test_list.append(user_df.iloc[split_idx:])\n",
    "\n",
    "train_df = pd.concat(train_list).reset_index(drop=True)\n",
    "test_df = pd.concat(test_list).reset_index(drop=True)\n",
    "\n",
    "train_df.to_csv(r\"D:\\Project\\web_mining\\notebooks\\ratings_train.csv\", index=False)\n",
    "test_df.to_csv(r\"D:\\Project\\web_mining\\notebooks\\ratings_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e1b78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lminh\\AppData\\Local\\Temp\\ipykernel_19496\\3267879284.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie meta shape: (46628, 25)\n",
      "Train final shape: (36757, 28)\n",
      "Test final shape : (8285, 28)\n",
      "Empty movie rows (train): 0\n",
      "Empty movie rows (test): 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_movie_id(df, col=\"movieId\"):\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[col])\n",
    "    df[col] = df[col].astype(int)\n",
    "    return df\n",
    "\n",
    "\n",
    "movies = pd.read_csv(r\"D:\\Project\\web_mining\\notebooks\\movies_cleaned.csv\", low_memory=False)\n",
    "credits = pd.read_csv(r\"D:\\Project\\web_mining\\notebooks\\credits_clean.csv\")\n",
    "keywords = pd.read_csv(r\"D:\\Project\\web_mining\\notebooks\\keywords_clean.csv\")\n",
    "\n",
    "movies = movies.rename(columns={\"id\": \"movieId\"})\n",
    "credits = credits.rename(columns={\"id\": \"movieId\"})\n",
    "keywords = keywords.rename(columns={\"id\": \"movieId\"})\n",
    "\n",
    "ratings_train = pd.read_csv(r\"D:\\Project\\web_mining\\notebooks\\ratings_train.csv\")\n",
    "ratings_test  = pd.read_csv(r\"D:\\Project\\web_mining\\notebooks\\ratings_test.csv\")\n",
    "\n",
    "movies = clean_movie_id(movies)\n",
    "credits = clean_movie_id(credits)\n",
    "keywords = clean_movie_id(keywords)\n",
    "ratings_train = clean_movie_id(ratings_train)\n",
    "ratings_test  = clean_movie_id(ratings_test)\n",
    "\n",
    "\n",
    "movie_meta = movies.merge(\n",
    "    credits,\n",
    "    on=\"movieId\",\n",
    "    how=\"inner\"\n",
    ").merge(\n",
    "    keywords,\n",
    "    on=\"movieId\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "print(\"Movie meta shape:\", movie_meta.shape)\n",
    "\n",
    "train_merged = ratings_train.merge(\n",
    "    movie_meta,\n",
    "    on=\"movieId\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "test_merged = ratings_test.merge(\n",
    "    movie_meta,\n",
    "    on=\"movieId\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "movie_feature_cols = train_merged.columns[4:]\n",
    "\n",
    "train_merged = train_merged.dropna(\n",
    "    subset=movie_feature_cols,\n",
    "    how=\"all\"\n",
    ")\n",
    "\n",
    "test_merged = test_merged.dropna(\n",
    "    subset=movie_feature_cols,\n",
    "    how=\"all\"\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Train final shape:\", train_merged.shape)\n",
    "print(\"Test final shape :\", test_merged.shape)\n",
    "\n",
    "print(\"Empty movie rows (train):\",\n",
    "      train_merged.iloc[:, 4:].isna().all(axis=1).sum())\n",
    "\n",
    "print(\"Empty movie rows (test):\",\n",
    "      test_merged.iloc[:, 4:].isna().all(axis=1).sum())\n",
    "\n",
    "\n",
    "train_merged.to_csv(\n",
    "    r\"D:\\Project\\web_mining\\notebooks\\ratings_train_clean.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "test_merged.to_csv(\n",
    "    r\"D:\\Project\\web_mining\\notebooks\\ratings_test_clean.csv\",\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7172a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã làm sạch toàn bộ cột list (bỏ id) và ghi đè file thành công!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "file_path = r\"D:\\Project\\web_mining\\notebooks\\ratings_test_clean.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "def clean_list_column(value):\n",
    "    if pd.isna(value):\n",
    "        return value\n",
    "\n",
    "    if isinstance(value, str):\n",
    "        try:\n",
    "            value = ast.literal_eval(value)\n",
    "        except:\n",
    "            return value\n",
    "\n",
    "    if isinstance(value, list):\n",
    "        cleaned = []\n",
    "        for item in value:\n",
    "            if isinstance(item, dict):\n",
    "                vals = [v for k, v in item.items() if k != \"id\"]\n",
    "                if len(vals) == 1:\n",
    "                    cleaned.append(vals[0])\n",
    "                else:\n",
    "                    cleaned.append(vals)\n",
    "            else:\n",
    "                cleaned.append(item)\n",
    "        return cleaned\n",
    "\n",
    "    return value\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].apply(clean_list_column)\n",
    "\n",
    "df.to_csv(file_path, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9836bda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "file_path = r\"D:\\Project\\web_mining\\notebooks\\ratings_train_clean.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "def clean_list_column(value):\n",
    "    if pd.isna(value):\n",
    "        return value\n",
    "\n",
    "    if isinstance(value, str):\n",
    "        try:\n",
    "            value = ast.literal_eval(value)\n",
    "        except:\n",
    "            return value\n",
    "\n",
    "    if isinstance(value, list):\n",
    "        cleaned = []\n",
    "        for item in value:\n",
    "            if isinstance(item, dict):\n",
    "                vals = [v for k, v in item.items() if k != \"id\"]\n",
    "                if len(vals) == 1:\n",
    "                    cleaned.append(vals[0])\n",
    "                else:\n",
    "                    cleaned.append(vals)\n",
    "            else:\n",
    "                cleaned.append(item)\n",
    "        return cleaned\n",
    "\n",
    "    return value\n",
    "\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].apply(clean_list_column)\n",
    "\n",
    "df.to_csv(file_path, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59074df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "def embed_overview_and_keywords(file_path, batch_size=32):\n",
    "    \"\"\"\n",
    "    Đọc file CSV, tạo embedding BERT cho:\n",
    "    - overview       \n",
    "    - keyword_names  \n",
    "    \"\"\"\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    def parse_list(x):\n",
    "        if pd.isna(x):\n",
    "            return []\n",
    "        if isinstance(x, list):\n",
    "            return x\n",
    "        try:\n",
    "            return ast.literal_eval(x)\n",
    "        except:\n",
    "            return []\n",
    "\n",
    "    df[\"overview\"] = df[\"overview\"].fillna(\"\")\n",
    "\n",
    "    overview_embeddings = model.encode(\n",
    "        df[\"overview\"].tolist(),\n",
    "        batch_size=batch_size,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "\n",
    "    df[\"overview_bert\"] = list(overview_embeddings)\n",
    "    df[\"keyword_names\"] = df[\"keyword_names\"].apply(parse_list)\n",
    "    df[\"keyword_text\"] = df[\"keyword_names\"].apply(\n",
    "        lambda x: \" and \".join(x) if len(x) > 0 else \"\"\n",
    "    )\n",
    "\n",
    "    keyword_embeddings = model.encode(\n",
    "        df[\"keyword_text\"].tolist(),\n",
    "        batch_size=batch_size,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "\n",
    "    df[\"keyword_names_bert\"] = list(keyword_embeddings)\n",
    "    df.drop(columns=[\"keyword_text\"], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3143e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 259/259 [01:19<00:00,  3.26it/s]\n",
      "Batches: 100%|██████████| 259/259 [00:34<00:00,  7.56it/s]\n"
     ]
    }
   ],
   "source": [
    "file_path = r\"D:\\Project\\web_mining\\notebooks\\ratings_test_clean.csv\"\n",
    "df_embedded = embed_overview_and_keywords(file_path)\n",
    "df_embedded.to_csv(r\"D:\\Project\\web_mining\\notebooks\\ratings_test_clean_bert.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fe6cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1149/1149 [05:53<00:00,  3.25it/s]\n",
      "Batches: 100%|██████████| 1149/1149 [02:21<00:00,  8.09it/s]\n"
     ]
    }
   ],
   "source": [
    "file_path = r\"D:\\Project\\web_mining\\notebooks\\ratings_train_clean.csv\"\n",
    "df_embedded = embed_overview_and_keywords(file_path)\n",
    "df_embedded.to_csv(r\"D:\\Project\\web_mining\\notebooks\\ratings_train_clean_bert.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ad8162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv(r\"D:\\Project\\web_mining\\notebooks\\ratings_train_clean_bert.csv\")\n",
    "\n",
    "RATING_THRESHOLD = 3.5\n",
    "\n",
    "df_train = df_train[df_train[\"rating\"] >= RATING_THRESHOLD]\n",
    "train_users = set(df_train[\"user_id\"].unique())\n",
    "\n",
    "df_train = df_train[df_train[\"user_id\"].isin(train_users)]\n",
    "\n",
    "def keep_latest_fraction(df, frac=0.5):\n",
    "    df = df.sort_values([\"user_id\", \"timestamp\"])\n",
    "\n",
    "    def select_latest(group):\n",
    "        n_keep = max(1, int(len(group) * frac))\n",
    "        return group.tail(n_keep)\n",
    "\n",
    "    return df.groupby(\"user_id\", group_keys=False).apply(select_latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8828d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_latest = keep_latest_fraction(df_train, frac=0.5)\n",
    "df_latest.to_csv(r\"D:\\Project\\web_mining\\notebooks\\ratings_50_latest.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
